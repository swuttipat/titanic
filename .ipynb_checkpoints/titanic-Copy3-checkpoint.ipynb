{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fcedd9f",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "### Overview\n",
    "The data has been split into two groups:\n",
    "* training set (train.csv)\n",
    "* test set (test.csv)\n",
    "\n",
    "**The training set** should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use *feature engineering* to create new features.\n",
    "\n",
    "**The test set** should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n",
    "\n",
    "We also include **gender_submission.csv**, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\n",
    "\n",
    "Data Dictionary\n",
    "\n",
    "| Variable |                 Definition                 |                       Key                      |\n",
    "|:---------|:-------------------------------------------|:-----------------------------------------------|\n",
    "| survival | Survival                                   | 0 = No, 1 = Yes                                |\n",
    "| pclass   | Ticket class                               | 1 = 1st, 2 = 2nd, 3 = 3rd                      |\n",
    "| sex      | Sex                                        |                                                |\n",
    "| Age      | Age in years                               |                                                |\n",
    "| sibsp    | # of siblings / spouses aboard the Titanic |                                                |\n",
    "| parch    | # of parents / children aboard the Titanic |                                                |\n",
    "| ticket   | Ticket number                              |                                                |\n",
    "| fare     | Passenger fare                             |                                                |\n",
    "| cabin    | Cabin number                               |                                                |\n",
    "| embarked | Port of Embarkation                        | C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "### Variable Notes\n",
    "**pclass**: A proxy for socio-economic status (SES) <br>\n",
    "1st = Upper <br>\n",
    "2nd = Middle <br>\n",
    "3rd = Lower <br>\n",
    "\n",
    "**age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "**sibsp**: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "**parch**: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e2e2dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['age', 'fare']\n",
    "categorical_features = ['pclass', 'sex', 'sibsp', 'parch', 'embarked']\n",
    "removeable_features = ['passengerid', 'name', 'ticket', 'cabin']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e122192",
   "metadata": {},
   "source": [
    "source:\n",
    "https://www.kaggle.com/competitions/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52590ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f048a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv').copy()\n",
    "test = pd.read_csv('test.csv').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "367120fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See Nan values\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dddb8489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns name into lowercase\n",
    "train.columns = [x.lower() for x in train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a23ea66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age mean: 29.69911764705882\n",
      "Age median: 28.0\n",
      "Age mode: 0    24.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Looking inside 'age' distribution\n",
    "plt.hist(train.age)\n",
    "plt.show()\n",
    "\n",
    "print('Age mean: {}'.format(train.age.mean()))\n",
    "print('Age median: {}'.format(train.age.median()))\n",
    "print('Age mode: {}'.format(train.age.mode()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ca43cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fare mean: 32.2042079685746\n",
      "fare median: 14.4542\n",
      "fare mode: 0    8.05\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Looking inside 'fare' distribution\n",
    "plt.hist(train.fare)\n",
    "plt.show()\n",
    "\n",
    "print('fare mean: {}'.format(train.fare.mean()))\n",
    "print('fare median: {}'.format(train.fare.median()))\n",
    "print('fare mode: {}'.format(train.fare.mode()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6181f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns name into lowercase\n",
    "def rename_cols(df):\n",
    "    df.columns = [x.lower() for x in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f9f4fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted columns\n",
    "def remove_unwanted_cols(df):\n",
    "    df = df.drop(labels=removeable_features, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ee29f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out outliers\n",
    "def filter_outlier(df):\n",
    "    # Select the columns to filter out outliers\n",
    "    cols_to_filter = numerical_features\n",
    "\n",
    "    # Calculate the quartiles and interquartile range\n",
    "    Q1 = df[cols_to_filter].quantile(0.25)\n",
    "    Q3 = df[cols_to_filter].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Set the lower and upper thresholds\n",
    "    lower_threshold = Q1 - 1.5 * IQR\n",
    "    upper_threshold = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Filter the df\n",
    "    df = df[~((df[cols_to_filter] < lower_threshold) | (df[cols_to_filter] > upper_threshold)).any(axis=1)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc3870fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer(df):\n",
    "    # Missing values imputer\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    # Create an imputer object with median strategy\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "    # Fit the imputer object on the age column\n",
    "    imputer.fit(df[numerical_features])\n",
    "\n",
    "    # Transform the age column\n",
    "    df[numerical_features] = imputer.transform(df[numerical_features])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cff8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply One-hot encode\n",
    "def one_hot(df):\n",
    "    df = pd.get_dummies(data=df, columns=categorical_features, drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f32750c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(df):\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Create standardscaler instace\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the instace on the selected columns\n",
    "    scaler.fit(df[numerical_features])\n",
    "\n",
    "    # Transform the selected columns\n",
    "    df[numerical_features] = scaler.transform(df[numerical_features])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6505923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(gen=False):\n",
    "    # Model training, predict, and evaluate\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    # Load the data\n",
    "    X, y = train.drop('survived', axis=1), train.survived\n",
    "\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the models\n",
    "    models = {'Logistic Regression': LogisticRegression(max_iter=500),\n",
    "              'Support Vector Machine': SVC(),\n",
    "              'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=21)}\n",
    "\n",
    "    # Iterate over the models\n",
    "    for name, model in models.items():\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        # Predict on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        print(\"Model: {}\".format(name))\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "        print(\"Precision: {:.4f}\".format(precision))\n",
    "        print(\"Recall: {:.4f}\".format(recall))\n",
    "        print()\n",
    "        \n",
    "        if gen == False :\n",
    "            pass\n",
    "        else:\n",
    "            generate_result(y_pred)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b3c1cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_result(y_pred):\n",
    "    # Create .csv predict result\n",
    "    result_dict = {'PassengerId':pd.read_csv('test.csv').copy().PassengerId,\n",
    "                   'Survived': y_pred}\n",
    "    df = pd.DataFrame(result_dict)\n",
    "    df.to_csv('{}.csv'.format(name),index=False)\n",
    "    print(\"Create .csv Model: {} Done\".format(name))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85f796b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79 (+/- 0.02)\n",
      "Accuracy: 0.81 (+/- 0.01)\n",
      "Accuracy: 0.82 (+/- 0.03)\n",
      "Best parameters for Logistic Regression:  {'C': 10, 'penalty': 'l2'}\n",
      "Best score for Logistic Regression:  0.8\n",
      "Best parameters for SVC:  {'C': 1, 'kernel': 'rbf'}\n",
      "Best score for SVC:  0.8065359477124183\n",
      "Best parameters for Random Forest:  {'max_depth': 6, 'n_estimators': 100}\n",
      "Best score for Random Forest:  0.8143790849673203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Define the parameter grid for Logistic Regression\n",
    "logreg_param_grid = {'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "                    'penalty': ['l2']}\n",
    "\n",
    "# Define the parameter grid for SVC\n",
    "svc_param_grid = {'C': [0.1, 1, 10],\n",
    "                  'kernel': ['linear', 'rbf']}\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "rf_param_grid = {'n_estimators': [50, 100, 200],\n",
    "                 'max_depth': [2, 4, 6, 8]}\n",
    "\n",
    "# Create the models\n",
    "logreg = LogisticRegression()\n",
    "svc = SVC()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Create the GridSearchCV objects\n",
    "logreg_grid = GridSearchCV(logreg, logreg_param_grid, cv=5)\n",
    "svc_grid = GridSearchCV(svc, svc_param_grid, cv=5)\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=5)\n",
    "\n",
    "# Load the data\n",
    "X_train, y_train = train.drop('survived', axis=1), train.survived\n",
    "\n",
    "# Fit the models to the training data\n",
    "logreg_grid.fit(X_train, y_train)\n",
    "svc_grid.fit(X_train, y_train)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "logreg_scores = cross_val_score(logreg_grid, X_train, y_train, cv=5)\n",
    "svc_scores = cross_val_score(svc_grid, X_train, y_train, cv=5)\n",
    "rf_scores = cross_val_score(rf_grid, X_train, y_train, cv=5)\n",
    "print(\"Logistic Regression Accuracy: %0.2f (+/- %0.2f)\" % (logreg_scores.mean(), logreg_scores.std()))\n",
    "print(\"SVC Accuracy: %0.2f (+/- %0.2f)\" % (svc_scores.mean(), svc_scores.std()))\n",
    "print(\"Random Forest Accuracy: %0.2f (+/- %0.2f)\" % (rf_scores.mean(), rf_scores.std()))\n",
    "\n",
    "# Print the best parameters and best score for each model\n",
    "print(\"Best parameters for Logistic Regression: \", logreg_grid.best_params_)\n",
    "print(\"Best score for Logistic Regression: \", logreg_grid.best_score_)\n",
    "\n",
    "print(\"Best parameters for SVC: \", svc_grid.best_params_)\n",
    "print(\"Best score for SVC: \", svc_grid.best_score_)\n",
    "\n",
    "print(\"Best parameters for Random Forest: \", rf_grid.best_params_)\n",
    "print(\"Best score for Random Forest: \", rf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07fda625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': 5, 'n_estimators': 100}\n",
      "Accuracy: 0.81 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "def grid_search():\n",
    "    # Model training, predict, and evaluate\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "    \n",
    "\n",
    "    # Load the data\n",
    "    X, y = train.drop('survived', axis=1), train.survived\n",
    "    \n",
    "    # Define the parameter grid\n",
    "    param_grid = {'n_estimators': [10, 50, 100], 'max_depth': [None, 5, 10]}\n",
    "\n",
    "    # Create the grid search object\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "\n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Print the best parameters\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "    # Evaluate the model using cross-validation\n",
    "    scores = cross_val_score(grid_search, X, y, cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "    \n",
    "train = pd.read_csv('train.csv').copy()\n",
    "train = rename_cols(train)\n",
    "train = remove_unwanted_cols(train)\n",
    "train = filter_outlier(train)\n",
    "train = imputer(train)\n",
    "train = one_hot(train)\n",
    "train = scaler(train)\n",
    "grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7039fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc2108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate result .csv \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train = train.drop('survived', axis=1)\n",
    "X_test = test\n",
    "y_train = train.survived\n",
    "\n",
    "# Initialize the models\n",
    "models = {'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "          'Support Vector Machine': SVC(),\n",
    "          'Random Forest': RandomForestClassifier(n_estimators=10)}\n",
    "\n",
    "# Iterate over the models\n",
    "for name, model in models.items():\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Create .csv predict result\n",
    "    result_dict = {'PassengerId':pd.read_csv('test.csv').copy().PassengerId,\n",
    "                   'Survived': y_pred}\n",
    "    df = pd.DataFrame(result_dict)\n",
    "    df.to_csv('{}.csv'.format(name),index=False)\n",
    "    print(\"Create .csv Model: {} Done\".format(name))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f7638a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.8235\n",
      "Precision: 0.8213\n",
      "Recall: 0.8235\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array length 153 does not match index length 418",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-3ef7e94c216c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sibsp_8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'parch_9'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mrun_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-af31d72a16cf>\u001b[0m in \u001b[0;36mrun_models\u001b[1;34m(gen)\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[0mgenerate_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-3cdb118ab129>\u001b[0m in \u001b[0;36mgenerate_result\u001b[1;34m(y_pred)\u001b[0m\n\u001b[0;32m      3\u001b[0m     result_dict = {'PassengerId':pd.read_csv('test.csv').copy().PassengerId,\n\u001b[0;32m      4\u001b[0m                    'Survived': y_pred}\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Create .csv Model: {} Done\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         ]\n\u001b[1;32m--> 287\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    413\u001b[0m                         \u001b[1;34mf\"length {len(index)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m                     )\n\u001b[1;32m--> 415\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: array length 153 does not match index length 418"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv').copy()\n",
    "test = pd.read_csv('test.csv').copy()\n",
    "\n",
    "train = rename_cols(train)\n",
    "train = remove_unwanted_cols(train)\n",
    "train = filter_outlier(train)\n",
    "train = imputer(train)\n",
    "train = one_hot(train)\n",
    "train = scaler(train)\n",
    "\n",
    "test = rename_cols(test)\n",
    "test = remove_unwanted_cols(test)\n",
    "test = imputer(test)\n",
    "test = one_hot(test)\n",
    "test = scaler(test)\n",
    "test = test.drop(['sibsp_8', 'parch_9'], axis=1)\n",
    "\n",
    "run_models(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e9994d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.8170\n",
      "Precision: 0.8153\n",
      "Recall: 0.8170\n",
      "\n",
      "Model: Support Vector Machine\n",
      "Accuracy: 0.7320\n",
      "Precision: 0.7400\n",
      "Recall: 0.7320\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.8497\n",
      "Precision: 0.8474\n",
      "Recall: 0.8497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quick precossing test\n",
    "train = pd.read_csv('train.csv').copy()\n",
    "test = pd.read_csv('test.csv').copy()\n",
    "\n",
    "train = rename_cols(train)\n",
    "train = remove_unwanted_cols(train)\n",
    "train = filter_outlier(train)\n",
    "train = imputer(train)\n",
    "# train = one_hot(train)\n",
    "# train = scaler(train)\n",
    "\n",
    "train.sex = train.sex.replace({'male':0, 'female':1})\n",
    "train.embarked = train.embarked.replace({'S':0, 'Q':1, 'C':2})\n",
    "\n",
    "test = rename_cols(test)\n",
    "test = remove_unwanted_cols(test)\n",
    "test = imputer(test)\n",
    "# test = one_hot(test)\n",
    "# test = scaler(test)\n",
    "# test = test.drop(['sibsp_8', 'parch_9'], axis=1)\n",
    "\n",
    "test.sex = test.sex.replace({'male':0, 'female':1})\n",
    "test.embarked = train.embarked.replace({'S':0, 'Q':1, 'C':2})\n",
    "run_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
